---
title: 'Final Project: Is College Worth It? (Tuition VS Salary)'
author: "Junjie Yang"
date: "5/2/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# I. Introduction
Is college worth it? Is college a good investment for your future? If it is, what kind of factors in college would have an impact on career performance?

On one hand, college could be worth it by leading to higher employment rates and higher career performance,  in terms of various financial measurements, than people who do not go to college. On the other hand, college tuition is constantly rising and is the same for student loan debt. 

In this project, four data sources are acquired from the US Department of Education, the Chronicle of Higher Education, the National Center for Education Statistics, and payscale.com. A final dataset in tidy version is created by conducting a significant amount of data cleansing and data wrangling techniques, so as to retrieve insightful information regarding the relationship between tuition or other factors in college and future career performance of college graduates.  

## Github Link

(Include several Data in tidy version, Rmd File, Report in PDF File and HTML File) 

### (https://github.com/Junjie-Dylan-Yang/Data-Wrangling-Project)


```{r include=FALSE}
# Call out packages that needed for the project
library(ggplot2)
library(repurrrsive)
library(tidyverse)
library(stringr)
library(dplyr)
library(tidytext)
library(wordcloud)
library(broom)
library(readxl)  
library(lubridate)
library(magrittr)
library(rvest)
library(xml2)
library(choroplethr)
library(choroplethrMaps)
library(countrycode)
library("xlsx")
```
# II. ETL process: Data Import and Data Cleansing
## 1,
### Import first data: tuition_cost
First data source, tuition_cost, is from "College tuition, Diversity, and Pay" in rfordatascience/tidetuesday/2020-03-10, which is originally acquired from the US Department of Education and the Chronicle of Higher Education. 

```{r include=FALSE}
tuition_cost <-read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-10/tuition_cost.csv')

```

### Data Cleaning for tuition_cost data
In the tuition_cost data, relevant columns are selected (name of the school, state, state code, type of the school, length of the degree). Also, room and board fee and tuition are combined as total tuition and fee.
```{r echo=FALSE}

tuition_cost = tuition_cost%>%
  select(name, state, state_code, type, degree_length, in_state_total, out_of_state_total)%>%
  mutate(in_state_tuition_and_fee = in_state_total, out_of_state_tuition_and_fee = out_of_state_total, in_state_total = NULL, out_of_state_total = NULL)
```

### Below is the snippet of tuition_cost data
```{r echo=F, results= 'show'}
head(tuition_cost,10)
```

## 2,
### Import second data: student_diversity
Second data source, student_diversity by college/university, along with school type, degree length, state, in-state vs out-of-state is from the Chronicle of Higher Education.
```{r include=FALSE}
student_diversity <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-10/student_diversity.csv')
```

### Data Cleaning for student_diversity data
In the student_diversity data, the main data cleansing task is to modify name of institution to match the “name” column and “state” column in the tuition_cost data, in order to combine dataset. Several data wrangling steps were applied. First is to change the column name “INSTITUTION” to “name”. After that, convert any abbreviation of University from “U.” to “University”. From the first glance, the name of state is located at the very end of the name of institution. The next step is to extract state from school name with the help of state.name which contains the list of all the state name and column “state” is created. Last but not least, state name inside the name of institution needed to remove. Using str_count to count the letters within state in each observation and str_sub help to keep the name of school only in the “name” column. Str_trim and str_squish are used to remove unnecessary spaces in "name".
```{r include=FALSE}
#Select relevant columns and change column name "INSTITUTION" to “name” to later binding datasets
student_diversity = student_diversity%>%
  rename(name = "INSTITUTION")%>%
  select(name, ENROLLMENT:WHITE, `TOTAL MINORITY` )

#Modify school name to match school name in the tuition_cost data 
student_diversity_cleaned = student_diversity%>%
  mutate(name = str_replace(name, "U.", "University "))

#Extract state from school name with the help of state.name which contains the list of all the state name
student_diversity_cleaned = student_diversity_cleaned%>%
  mutate(state = str_extract(name, paste0(state.name, collapse = "|")))

#Clear any unnecessary spaces in "name" and remove the state at the end of "name"
student_diversity_cleaned$name = str_squish(student_diversity_cleaned$name)

position_to_remove = str_count(student_diversity_cleaned$state)+1
student_diversity_cleaned$name = str_sub(student_diversity_cleaned$name, 1, -(position_to_remove))

student_diversity_cleaned$name = str_trim(student_diversity_cleaned$name)
```

### Below is the snippet of student_diversity_cleaned data
```{r echo=F, results= 'show'}
head(student_diversity_cleaned,10)
```

### Combine tuition_cost and student_diversity data based on "name" and "state"
So far, student_diversity and tuition_cost are modified to share two common column, “name” – name of the school and “state” – the state that the school is located. Thus, student_diversity and tuition_cost datasets are merged for late development. There are a few schools appears in the tuition_cost dataset but not in the student_diversity and “NA” value appear. It is reasonable and schools with “NA” value are removed from the combined dataset. The combined dataset is arranged by state and the name of the school.
```{r include=FALSE}
tuition_with_diversity = left_join(tuition_cost, student_diversity_cleaned, by = c("name","state"))%>%
  na.omit(tuition_with_diversity)

tuition_with_diversity = tuition_with_diversity[order(tuition_with_diversity$state, tuition_with_diversity$name),]
```

### Below is the snippet of the combined dataset, tuition_with_diversity
```{r echo=F, results= 'show'}
head(tuition_with_diversity,10)
```
## 3,
### Import third data: Best_School
Third data source, best_school is html data, acquired from the from the payscale.com. It contains all the schools in United States that are arranged by various measurement of career performance, such as "Early Career Pay" and "Mid Career Pay.

#### Problem encountered
When importing html data from https://www.payscale.com/college-salary-report/bachelors, I realized the table only include the data with the top 25 schools in the United States, descending by measurement of career performance. That's the issue that I am not expecting. Moreover, this is the first page in the web and there are 63 pages in total, which consists all the school data.
```{r include=FALSE}
#Initial datapull
url <- ("https://www.payscale.com/college-salary-report/bachelors")

best_school_test = url %>% 
  read_html() %>% 
  html_table(fill = TRUE) %>% 
  .[[1]]
```

#### Problem resolved
Instead of importing data 63 times to get the entire dataset, one alternative webpage is found by navigating the payscale.com. The page “Best Schools By State” (https://www.payscale.com/college-salary-report/best-schools-by-state) outlays all the best schools ranked by measurement of career performance of all 50 states. Clicking on each state would direct to the schools data within that particular state. In order to import the entire data, I first convert the string format in the list of state.name to match the url (“New York” to “New-York”). Then, a data frame is created. For-Loop is implemented to import all 50 states data to the R environment and to keep loading data into the data frame to form a complete dataset, “Best_School”, for data cleansing.

```{r echo=FALSE}
store_url = "https://www.payscale.com/college-salary-report/best-schools-by-state/bachelors/"

#Modify state in state.name to match the format in url
state_name = str_replace_all(state.name, " ","-")

#Initial dataframe to start with
Best_School = best_school_test

#Keep appending data to dataframe
for (i in 1:length(state_name)){
  url = paste0(store_url,state_name[i])
  school_state_data = paste0("Best_School",i)
  
  school_state_data = url %>% 
    read_html() %>% 
    html_table(fill = TRUE) %>% 
    .[[1]]
  
  Best_School = rbind(Best_School, school_state_data)
}

#Remove rows in initial dataframe
Best_School = Best_School[-(1:25),]
```


### Data Cleaning for Best_School data
First step is to modify the column name "School Name" to "name" and to keep the exact name of school only, in order to match the tuition_with_diversity dataset for binding. After that, there are several data cleansing steps that are applied to other columns. Only numeric values are extracted from the column, “Rank”, "Early Career Pay", "Mid-Career Pay", "% High Meaning", "% STEM Degrees". One lesson learned is that R suggests to use parse_number(), instead of extract_numeric() for extracting numeric value.

 
```{r include=FALSE}
#Modify "School Name" to "name" to match the tuition_with_diversity dataset
Best_School_clean = Best_School%>%
  rename(name = "School Name")

#Extract school name
Best_School_clean$name = str_remove(Best_School_clean$name, "School Name:")

Best_School_clean$`Mid-Career Pay` = str_remove(Best_School_clean$`Mid-Career Pay`, "Mid-Career Pay:")

#Extract number content from certain column  
Best_School_clean = Best_School_clean%>%
  mutate(
  Rank = parse_number(Best_School_clean$Rank),
  "Early Career Pay" = parse_number(Best_School_clean$`Early Career Pay`),
  "Mid-Career Pay" = parse_number(Best_School_clean$`Mid-Career Pay`),
  "% High Meaning" = parse_number(Best_School_clean$`% High Meaning`),
  "% STEM Degrees" = parse_number(Best_School_clean$`% STEM Degrees`),
  )

Best_School_clean = Best_School_clean%>%
  select(name, "Early Career Pay", "Mid-Career Pay", "% High Meaning", "% STEM Degrees" )
```

### Below is the snippet of Best_School_clean data
```{r echo=F, results= 'show'}
head(Best_School_clean,10)
```

### Combine Best_School_clean data and tuition_with_diversity to form the final data 
Finally, Best_School_clean data, which contains different measurements of career performance, merges with tuition_with_diversity data, which contains detailed school information including tuition and race. The column both datasets have in common is “name” and left_join is performed. Similar to the previous merged dataset, schools with “NA” are removed from the dataset. 

### Create new variables: 
Mid_career_pay_paidoff: different between median salary for alumni with 10+ years experience and out of state tuition and fee.

Early_career_pay_paidoff: different between median salary for alumni with 0-5 years experience and out of state tuition and fee.
```{r include=FALSE}
Fianl_data = left_join(Best_School_clean, tuition_with_diversity, by = "name") %>%
  na.omit(Fianl_data)
rownames(Fianl_data)=1:nrow(Fianl_data)

Fianl_data$Mid_career_pay_paidoff = Fianl_data$`Mid-Career Pay` - Fianl_data$out_of_state_tuition_and_fee

Fianl_data$Early_career_pay_paidoff = Fianl_data$`Early Career Pay` - Fianl_data$out_of_state_tuition_and_fee

```

### Below is the snippet of the Final_data 
There are 622 observations in all 50 states in United States and each college or university is a unique observation. This is the tidy version of the final data and it will be stored as a csv file.

### Attribute Information
Below information is from payscale.com:

"Early Career Pay" is defined as median salary for alumni with 0-5 years experience. 

"Mid-Career Pay" is defined as Median salary for alumni with 10+ years experience. 

"% High Meaning" is defined as the percentage of alumni who say their work makes the world a better place. 

"% STEM Degrees" is defined as the percentage of degrees awarded in science, technology, engineering or a math subjects.

```{r echo=F, results= 'show'}
head(Fianl_data,10)
```
#### The tidy version of the final data, "Fianl_data" is saved under the name "Tidy_Data.xlsx" local location and will be committed from Github desktop to Github.com repository (https://github.com/Junjie-Dylan-Yang/Data-Wrangling-Project)
```{r include=FALSE}
getwd()
write.xlsx(Fianl_data, "Tidy_Data.xlsx", row.names = FALSE)
```

## 4,
### Import fourth data: historical_tuition
The last data source, historical_tuition, is from "College tuition, Diversity, and Pay" in rfordatascience/tidetuesday/2020-03-10, which is originally acquired from the National Center for Education Statistics.(https://nces.ed.gov/fastfacts/display.asp?id=76)

```{r include=FALSE}
historical_tuition =read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-10/historical_tuition.csv')

```
The fourth data, historical_tuition, is tidy and contains the information of the trends in the cost of college education. Therfore, "historical_tuition“ is saved under the name of "Tuition_trend.xlsx" in the same location of The tidy version of the final data.
```{r include=FALSE}
write.xlsx(historical_tuition, "Tuition_trend.xlsx")
```

### Below is the snippet of tuition_cost data
```{r echo=F, results= 'show'}
head(historical_tuition,10)
```

# III. Data Analysis by plot and tables
After a series of data wrangling and data cleansing conducted on several data sources from above, final data in tidy version, "Final_data" and "historical_tuition" data are ready to use for data analysis.

## 1, Tuition Trend: Going upward over time
Split the historical_tuition into 3 subset dataset by tuition type: "All Constant", "4 Year Constant", and "2 Year Constant". From below plots, it clearly shows that, college tuition increases at a rapid rate over time, on schools with all three tuition types. 
```{r include=FALSE}
#filter for different tuition type
All_Constant = historical_tuition%>%
  filter(historical_tuition$tuition_type == "All Constant")
Four_Year_Constant = historical_tuition%>%
  filter(historical_tuition$tuition_type == "4 Year Constant")
Two_Year_Constant = historical_tuition%>%
  filter(historical_tuition$tuition_type == "2 Year Constant")


```

```{r echo=F, results= 'show'}
ggplot(All_Constant, mapping = aes(All_Constant$year, All_Constant$tuition_cost, color = type)) +geom_point()+ coord_flip() + ggtitle('Tuition by Year for School with Tuition Type: All Constant')+theme(plot.title = element_text(hjust = 0.5))+facet_wrap(~All_Constant$type, ncol = 3, scales = 'free')+ylab("Tuition in USD") +xlab("Year")

ggplot(Four_Year_Constant, mapping = aes(Four_Year_Constant$year, Four_Year_Constant$tuition_cost, color = type)) +geom_point()+ coord_flip() + ggtitle('Tuition by Year for School with Tuition Type: 4 Year Constant')+theme(plot.title = element_text(hjust = 0.5))+facet_wrap(~Four_Year_Constant$type, ncol = 3, scales = 'free')+ylab("Tuition in USD")+xlab("Year")

ggplot(Two_Year_Constant, mapping = aes(Two_Year_Constant$year, Two_Year_Constant$tuition_cost, color = type)) +geom_point()+ coord_flip() + ggtitle('Tuition by Year for School with Tuition Type: 2 Year Constant')+theme(plot.title = element_text(hjust = 0.5))+facet_wrap(~Two_Year_Constant$type, ncol = 3, scales = 'free')+ylab("Tuition in USD")+xlab("Year")
```

## 2, Take a look at the final data, "Final_data" at the level of states.
Create another dataset "state_data" at state level from the final data, "Final_data". All numeric values are summarised by taking the average respect to each state. This dataset is also saved in the same location as the final data.

```{r include=FALSE}
state_data = Fianl_data%>%
  group_by(Fianl_data$state)%>%
  summarise(
    count = n(),
    Mean_Early_Career_Pay = mean(`Early Career Pay`),
    Mean_Mid_Career_pay = mean(`Mid-Career Pay`),
    Mean_High_Meaning = mean(`% High Meaning`),
    Mean_STEM_Degree = mean(`% STEM Degrees`),
    Mean_Out_Of_State_Cost = mean(`out_of_state_tuition_and_fee`),
    Mean_Enrollment = mean(`ENROLLMENT`),
    Mean_Minority = mean(`TOTAL MINORITY`),
    Mean_early_paidoff = mean(`Early_career_pay_paidoff`),
    Mean_mid_paidoff = mean(`Mid_career_pay_paidoff`)
    )%>%
  rename(state = "Fianl_data$state")
write.xlsx(state_data, "state_data.xlsx")

```

### Plots that show insightful information regarding tuition and career performance at the state level


(1) As people expected, big states like Pennsylvania, New York, California, and Massachusetts have the highest average out-of-state college cost because of high income and high levels of consumption rate.

```{r echo=F, results= 'show'}
#Tuition Analysis
tuition_analysis = state_data%>%
  arrange(desc(state_data$Mean_Out_Of_State_Cost))%>%
  .[1:10,]

ggplot(tuition_analysis, mapping = aes(reorder(tuition_analysis$state,tuition_analysis$Mean_Out_Of_State_Cost ), tuition_analysis$Mean_Out_Of_State_Cost, fill = tuition_analysis$Mean_Out_Of_State_Cost)) +geom_bar(stat = "identity")+ coord_flip() + ggtitle('Top 10 States by Average out-of-state Tuition+Fee')+theme(plot.title = element_text(hjust = 0.5))+ylab("Tuition in USD")+xlab("State")+theme(legend.title = element_blank())
```

(2) There is no suprise that people graduated from colleges/universities big states like Pennsylvania, New York, Massachusetts, and California would have better career performance in terms of early-salary pay(0-5 year experience) and mid-salary pay(5-10 year experience) because schools in those states have the most wide range of education resources.

```{r echo=F, results= 'show'}
#Salary Analysis
mid_salary_analysis = state_data%>%
  arrange(desc(state_data$Mean_Early_Career_Pay))%>%
  .[1:10,]

early_salary_analysis = state_data%>%
  arrange(desc(state_data$Mean_Early_Career_Pay))%>%
  .[1:10,]


par(mfrow=c(1,2))
ggplot(mid_salary_analysis, mapping = aes(reorder(mid_salary_analysis$state,mid_salary_analysis$Mean_Mid_Career_pay ), mid_salary_analysis$Mean_Mid_Career_pay, fill = mid_salary_analysis$Mean_Mid_Career_pay)) +geom_bar(stat = "identity")+ coord_flip() + ggtitle('Top 10 States by Average Mid-Salary (5-10 Years Experience)')+theme(plot.title = element_text(hjust = 0.5))+ylab("Average Salary in USD")+xlab("State")+theme(legend.title = element_blank())

ggplot(early_salary_analysis, mapping = aes(reorder(early_salary_analysis$state,early_salary_analysis$Mean_Early_Career_Pay ), early_salary_analysis$Mean_Early_Career_Pay, fill = early_salary_analysis$Mean_Early_Career_Pay)) +geom_bar(stat = "identity")+ coord_flip() + ggtitle('Top 10 States by Average Early-Salary (0-5 Years Experience)')+theme(plot.title = element_text(hjust = 0.5))+ylab("Average Salary in USD")+xlab("State")+theme(legend.title = element_blank())


```

(3) Interesting Finding:

If poeple consider going to college is a good investment and decide to go to the colleges in big states like Pennsylvania, New York, Massachusetts, and California based on the above plots of career performance in terms of salary, they should also take a look at the bar plots below.

"Mean_early_paidoff" and "Mean_mid_paidoff" are created based on "Early_career_pay_paidoff" and "Mid_career_pay_paidoff" during previous data cleansing steps in Part II. 

They are defined as the average different between median salary for alumni with 0-5 and 5-10 years experience and out of state tuition and fee in different states.

From the below plots and maps, the schools in the states that have the best investment value in terms of "Mean_early_paidoff" and "Mean_mid_paidoff" are Ulah, Wyoming, and New MExico, etc. The school in big states like New York and Pennsylvania are not in the top-10 list. One reason would be that those schools in the big states have the most wide range of education resources but at the same time, their college cost is way higher than the schools in other states.


```{r echo=F, results= 'show', warning = FALSE}
#Paidoff Analysis (Tuition vs Salary)
Paidoff_early = state_data%>%
  select(state, "Mean_early_paidoff")
Paidoff_early = Paidoff_early%>%
  arrange(desc(Paidoff_early$Mean_early_paidoff))%>%
  .[1:10,]

Paidoff_mid = state_data%>%
  select(state, "Mean_mid_paidoff")
Paidoff_mid = Paidoff_mid%>%
  arrange(desc(Paidoff_mid$Mean_mid_paidoff))%>%
  .[1:10,]

par(mfrow=c(2,2))
ggplot(Paidoff_early, mapping = aes(reorder(Paidoff_early$state,Paidoff_early$Mean_early_paidoff ), Paidoff_early$Mean_early_paidoff, fill = Paidoff_early$Mean_early_paidoff)) +geom_bar(stat = "identity")+ coord_flip() + ggtitle('Top 10 States by Average of [Early Salary(0-5 Years Experience) - College Cost]')+theme(plot.title = element_text(hjust = 0.5))+ylab("Difference in USD")+xlab("State")+theme(legend.title = element_blank())

Paidoff_early_map = state_data%>%
  select(state, "Mean_early_paidoff")
Paidoff_early_map$state = tolower(Paidoff_early_map$state)
Paidoff_early_map = Paidoff_early_map%>%
  rename(region = state, value = "Mean_early_paidoff")
state_choropleth(Paidoff_early_map, title = 'Average of [Early Salary(0-5 Years Experience) - College Cost] in US')

ggplot(Paidoff_mid, mapping = aes(reorder(Paidoff_mid$state,Paidoff_mid$Mean_mid_paidoff ), Paidoff_mid$Mean_mid_paidoff, fill = Paidoff_mid$Mean_mid_paidoff)) +geom_bar(stat = "identity")+ coord_flip() + ggtitle('Top 10 States by Average of [Mid Salary(5-10 Years Experience) - College Cost]')+theme(plot.title = element_text(hjust = 0.5))+ylab("Difference in USD")+xlab("State")+theme(legend.title = element_blank())

Paidoff_mid_map = state_data%>%
  select(state, "Mean_mid_paidoff")
Paidoff_mid_map$state = tolower(Paidoff_mid_map$state)
Paidoff_mid_map = Paidoff_mid_map%>%
  rename(region = state, value = "Mean_mid_paidoff")
state_choropleth(Paidoff_mid_map, title = 'Average of [Mid Salary(5-10 Years Experience) - College Cost] in US')
```


## 3, Take a look at the final data, "Final_data" at the level of school type (Private vs Public, 4yr degress vs 2yr degrees)
```{r echo=F, results= 'show'}


```


## 4, Linear Model on each states (Factors that impact salary) and save for future development and improvement


# IV. User Interface
















